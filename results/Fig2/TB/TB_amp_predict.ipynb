{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47d3df06-cd97-4aec-b3ca-f5968f03f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "# load in config with GPSC paths\n",
    "with open(\"config/TB_reps.yaml\", 'r') as file:\n",
    "    config=yaml.safe_load(file)\n",
    "\n",
    "# extract GPSCs\n",
    "gpscs = config['samples'] \n",
    "\n",
    "# set params\n",
    "amplicon_stats = list()\n",
    "xlen = 2200\n",
    "\n",
    "total_genome_coverages={}\n",
    "amplicon_positions={}\n",
    "\n",
    "with open('output.txt', 'w') as f:\n",
    "\n",
    "    for gpsc, fasta_file in gpscs.items():\n",
    "        records = list(SeqIO.parse(fasta_file, \"fasta\"))\n",
    "\n",
    "        # calculate length of the genome for each GPSC\n",
    "        genome_length=sum(len(record.seq) for record in records)\n",
    "\n",
    "        # initialize amplicon genome coverage for each GPSC separately \n",
    "        total_genome_coverage=0\n",
    "\n",
    "        # initialize set of covered positions across each GPSC \n",
    "        covered_positions = set()\n",
    "\n",
    "        # intitialize list of amplicon positions \n",
    "        amplicon_positions[gpsc] = []\n",
    "\n",
    "        print(f\"Processing {gpsc}...\", file=f)  \n",
    "\n",
    "        # load the samtools depth file\n",
    "        depth_file = os.path.join(\"samtools_depth\", f\"{gpsc}.depth\")\n",
    "        df = pd.read_csv(depth_file, sep=\"\\t\", names=[\"Ref\", \"Pos\", \"Depth\"])\n",
    "\n",
    "        # get the positions where the depth is 1 (primer binding sites)\n",
    "        primer_binding_sites = df[df[\"Depth\"] == 1][\"Pos\"].tolist()\n",
    "\n",
    "        for p1loc in primer_binding_sites:\n",
    "            # find the next primer binding site within xlen bases\n",
    "            p2loc = next((pos for pos in primer_binding_sites if p1loc < pos <= p1loc + xlen), None)\n",
    "\n",
    "            if p2loc is not None:\n",
    "                # calculate the amplicon stats\n",
    "                amplicon_stats.append((gpsc, gpsc, gpsc, gpsc, gpsc, gpsc, 0, 0, 0, p1loc, p2loc))\n",
    "                covered_positions.update(range(p1loc, p2loc+1))\n",
    "                # store amplicon positions \n",
    "                amplicon_positions[gpsc].append((p1loc, p2loc))\n",
    "                print(f\"Detected amplicon from {p1loc} to {p2loc}.\", file=f)  \n",
    "\n",
    "                # calculate the length of the amplicon and add to total genome coverage\n",
    "                total_genome_coverage += p2loc-p1loc \n",
    "\n",
    "        # calculate predicted % coverage \n",
    "        coverage_percentage = (len(covered_positions) / genome_length) * 100\n",
    "\n",
    "        # update dictionary \n",
    "        total_genome_coverages[gpsc] = coverage_percentage\n",
    "\n",
    "        print(f\"Total genome coverage for {gpsc}: {total_genome_coverages[gpsc]}%\", file=f) \n",
    "\n",
    "colnames=[\"pid1\",\"pid2\",\"set1\",\"set2\",\n",
    "          \"pseq1\",\"pseq2\",\n",
    "          \"max_hdist\",\"hdist1\",\"hdist2\",\n",
    "          \"p1loc\",\"p2loc\"]\n",
    "coltypes=[\"<U30\", \"<U30\", \"<U30\", \"<U30\",\n",
    "          \"<U30\", \"<U30\",\n",
    "          float, float, float,\n",
    "          int, int]\n",
    "\n",
    "dt = {'names':colnames, 'formats':coltypes}\n",
    "\n",
    "amplicon_statsnp = np.array(amplicon_stats,\n",
    "                     dtype=dt)\n",
    "\n",
    "np.save(\"amplicon_statstab.npy\", amplicon_statsnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12b9cf68-27e0-42fd-a028-7ca61c798545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR1175079: 95.4265383183824%\n",
      "SRR1173445: 95.50288153604549%\n",
      "ERR181435: 95.50296735198772%\n",
      "SRR1019139: 95.50262349418551%\n",
      "SRR1163294: 95.44026889390904%\n",
      "SRR1180462: 95.44021418453445%\n",
      "ERR234202: 95.50305904327543%\n",
      "SRR998654: 95.46811755574576%\n",
      "ERR229952: 95.48011264525246%\n",
      "SRR671749: 95.50288225920158%\n",
      "ERR133985: 95.42781159597034%\n",
      "SRR1173640: 95.42677743650191%\n",
      "H37Rv: 95.50267344768211%\n",
      "NC_019950: 90.9711747020706%\n"
     ]
    }
   ],
   "source": [
    "for gpsc, coverage in total_genome_coverages.items():\n",
    "    print(f\"{gpsc}: {coverage}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2ea327a-8ed7-4399-8166-74b48d4d718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR1175079: 4411538 bp\n",
      "SRR1173445: 4411536 bp\n",
      "ERR181435: 4411509 bp\n",
      "SRR1019139: 4411483 bp\n",
      "SRR1163294: 4411554 bp\n",
      "SRR1180462: 4411523 bp\n",
      "ERR234202: 4411510 bp\n",
      "SRR998654: 4411456 bp\n",
      "ERR229952: 4411371 bp\n",
      "SRR671749: 4411470 bp\n",
      "ERR133985: 4411498 bp\n",
      "SRR1173640: 4411550 bp\n",
      "H37Rv: 4411532 bp\n",
      "NC_019950: 4432426 bp\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "# Load the config file\n",
    "with open(\"config/TB_reps.yaml\", 'r') as file:\n",
    "    config=yaml.safe_load(file)\n",
    "\n",
    "# Extract the GPSCs\n",
    "gpscs = config['samples']\n",
    "\n",
    "# Initialize a dictionary to store the genome lengths\n",
    "genome_lengths = {}\n",
    "\n",
    "# Calculate and store the length of each sequence\n",
    "for gpsc, fasta_file in gpscs.items():\n",
    "    records = list(SeqIO.parse(fasta_file, \"fasta\"))\n",
    "    genome_length = sum(len(record.seq) for record in records)\n",
    "    genome_lengths[gpsc] = genome_length  # Store the genome length in the dictionary\n",
    "\n",
    "#Print the genome lengths\n",
    "for gpsc, length in genome_lengths.items():\n",
    "    print(f\"{gpsc}: {length} bp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01b0b89d-10fc-486c-8081-6b529a988f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# initialize empty list\n",
    "amplicon_data = []\n",
    "\n",
    "# max allowed for size of amplicons\n",
    "max_amplicon_size = 2000\n",
    "\n",
    "# iterate over gpsc seqs\n",
    "for gpsc, positions in amplicon_positions.items():\n",
    "    # filter out none vals to fix none error\n",
    "    filtered_positions = [pos for pos in positions if pos is not None]\n",
    "    \n",
    "    if filtered_positions:\n",
    "        # sort start and end positions of amplicons\n",
    "        filtered_positions.sort()\n",
    "        start = filtered_positions[0][0]  \n",
    "        end = filtered_positions[0][1]  \n",
    "\n",
    "        for current_start, current_end in filtered_positions[1:]:\n",
    "            # check if the current start is contiguous with the previous end and does not exceed max size\n",
    "            if current_start <= end + 1 and (current_end - start) <= max_amplicon_size:\n",
    "                end = max(end, current_end)  \n",
    "            else:\n",
    "                # if not contiguous or exceeds max size, save the previous contiguous sequence and start a new one\n",
    "                amplicon_data.append({'Sequence': gpsc, 'Start': start, 'End': end})\n",
    "                start, end = current_start, current_end  \n",
    "\n",
    "        # save last contigious sequence after each loop\n",
    "        amplicon_data.append({'Sequence': gpsc, 'Start': start, 'End': end})\n",
    "\n",
    "# convert dict to df\n",
    "amplicon_positions_df = pd.DataFrame(amplicon_data)\n",
    "\n",
    "# export\n",
    "amplicon_positions_df.to_csv('fwdandrev_amplicon_positions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f2a62a1-5d1f-4317-a07f-38f3dea62336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create csv file containing predicted genome coverage for each sequence based on predicted amplicon coverage\n",
    "total_genome_coverages_df = pd.DataFrame([total_genome_coverages])\n",
    "\n",
    "total_genome_coverages_df.to_csv('genome_coverage_pc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc50ee06-71bd-4239-bec0-4bffa3581bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "            ------------------------------------------------------ separate fwd and rev amplicon predictions --------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b99e8b-06fe-4afa-9bef-a7e1a30d8605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "# load in config with GPSC paths\n",
    "with open(\"config/TB_reps.yaml\", 'r') as file:\n",
    "    config=yaml.safe_load(file)\n",
    "\n",
    "# extract GPSCs\n",
    "gpscs = config['samples'] \n",
    "\n",
    "# set params\n",
    "amplicon_stats = list()\n",
    "xlen = 2200\n",
    "\n",
    "total_genome_coverages={}\n",
    "amplicon_positions={}\n",
    "\n",
    "with open('output.txt', 'w') as f:\n",
    "\n",
    "    for gpsc, fasta_file in gpscs.items():\n",
    "        records = list(SeqIO.parse(fasta_file, \"fasta\"))\n",
    "\n",
    "        # calculate length of the genome for each GPSC\n",
    "        genome_length=sum(len(record.seq) for record in records)\n",
    "\n",
    "        # initialize amplicon genome coverage for each GPSC separately \n",
    "        total_genome_coverage=0\n",
    "\n",
    "        # initialize set of covered positions across each GPSC \n",
    "        covered_positions = set()\n",
    "\n",
    "        # intitialize list of amplicon positions \n",
    "        amplicon_positions[gpsc] = []\n",
    "\n",
    "        print(f\"Processing {gpsc}...\", file=f)  \n",
    "\n",
    "        # load the samtools depth file\n",
    "        fwd_depth_file = os.path.join(\"samtools_depth_indiv_primers\", f\"{gpsc}_fwd.depth\")\n",
    "        rev_depth_file = os.path.join(\"samtools_depth_indiv_primers\", f\"{gpsc}_rev.depth\")\n",
    "        \n",
    "        # load each depth file into a df\n",
    "        fwd_df = pd.read_csv(fwd_depth_file, sep=\"\\t\", names=[\"Ref\", \"Pos\", \"Depth\"])\n",
    "        fwd_df['Primer'] = 'fwd'\n",
    "\n",
    "        rev_df = pd.read_csv(rev_depth_file, sep=\"\\t\", names=[\"Ref\", \"Pos\", \"Depth\"])\n",
    "        rev_df['Primer'] = 'rev'\n",
    "\n",
    "        # combine the dfs\n",
    "        df = pd.concat([fwd_df, rev_df])\n",
    "\n",
    "        # filter for fwd and rev positions separately \n",
    "        fwd_primer_binding_sites = df[(df[\"Depth\"] == 1) & (df[\"Primer\"] == 'fwd')][\"Pos\"].tolist()\n",
    "\n",
    "        rev_primer_binding_sites = df[(df[\"Depth\"] == 1) & (df[\"Primer\"] == 'rev')][\"Pos\"].tolist()\n",
    "\n",
    "        def calculate_amplicons(primer_binding_sites, gpsc, xlen, amplicon_positions, amplicon_stats, covered_positions, total_genome_coverage, f, primer_direction):\n",
    "            for p1loc in primer_binding_sites:\n",
    "        # find the next primer binding site within xlen bases\n",
    "                p2loc = next((pos for pos in primer_binding_sites if p1loc < pos <= p1loc + xlen), None)\n",
    "\n",
    "                if p2loc is not None:\n",
    "            # amp stats\n",
    "                    amplicon_stats.append((gpsc, gpsc, gpsc, gpsc, gpsc, gpsc, 0, 0, 0, p1loc, p2loc, primer_direction))\n",
    "                    covered_positions.update(range(p1loc, p2loc+1))\n",
    "            # ID amp positions\n",
    "                    amplicon_positions[gpsc].append((p1loc, p2loc))\n",
    "                    print(f\"Detected amplicon from {p1loc} to {p2loc}.\", file=f)  \n",
    "\n",
    "            # get total genome coverage\n",
    "                    total_genome_coverage += p2loc - p1loc\n",
    "\n",
    "        # calculate predicted % coverage \n",
    "            coverage_percentage = (len(covered_positions) / genome_length) * 100\n",
    "\n",
    "        # update dictionary \n",
    "            total_genome_coverages[gpsc] = coverage_percentage\n",
    "\n",
    "        # summarize fwd amplicons\n",
    "        calculate_amplicons(fwd_primer_binding_sites, gpsc, xlen, amplicon_positions, amplicon_stats, covered_positions, total_genome_coverage, f, 'fwd')\n",
    "        # summarize rev amplicons\n",
    "        calculate_amplicons(rev_primer_binding_sites, gpsc, xlen, amplicon_positions, amplicon_stats, covered_positions, total_genome_coverage, f, 'rev')\n",
    "\n",
    "colnames = [\"pid1\", \"pid2\", \"set1\", \"set2\",\n",
    "            \"pseq1\", \"pseq2\",\n",
    "            \"max_hdist\", \"hdist1\", \"hdist2\",\n",
    "            \"p1loc\", \"p2loc\", \"PrimerDirection\"]\n",
    "coltypes = [\"<U30\", \"<U30\", \"<U30\", \"<U30\",\n",
    "            \"<U30\", \"<U30\",\n",
    "            float, float, float,\n",
    "            int, int, \"<U3\"]\n",
    "\n",
    "dt = {'names': colnames, 'formats': coltypes}\n",
    "\n",
    "amplicon_statsnp = np.array(amplicon_stats,\n",
    "                     dtype=dt)\n",
    "\n",
    "np.save(\"amplicon_statstab.npy\", amplicon_statsnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12e8e49b-c9d3-486c-ac46-71f99dc8bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Initialize a dictionary to group amplicons by sequence and primer type\n",
    "grouped_amplicons = {}\n",
    "\n",
    "# Define the maximum allowed size for amplicons\n",
    "max_amplicon_size = 2000\n",
    "\n",
    "# Iterate over amplicon_stats, assuming the last element is primer_direction, and the first is gpsc\n",
    "for amplicon in amplicon_stats:\n",
    "    *_, p1loc, p2loc, primer_direction = amplicon\n",
    "    gpsc = amplicon[0]\n",
    "    key = (gpsc, primer_direction)\n",
    "    if key not in grouped_amplicons:\n",
    "        grouped_amplicons[key] = []\n",
    "    grouped_amplicons[key].append((p1loc, p2loc))\n",
    "\n",
    "# Initialize list for contiguous amplicons\n",
    "contiguous_amplicons = []\n",
    "\n",
    "# Process each group for contiguity\n",
    "for (gpsc, primer_direction), positions in grouped_amplicons.items():\n",
    "    positions.sort()\n",
    "    start, end = positions[0]\n",
    "    \n",
    "    for current_start, current_end in positions[1:]:\n",
    "        # Check if contiguous and does not exceed max amplicon size\n",
    "        if current_start <= end + 1 and (current_end - start) <= max_amplicon_size:\n",
    "            end = max(end, current_end)\n",
    "        else:\n",
    "            contiguous_amplicons.append([gpsc, start, end, primer_direction])\n",
    "            start, end = current_start, current_end\n",
    "    # After processing all positions, append the last contiguous segment\n",
    "    contiguous_amplicons.append([gpsc, start, end, primer_direction])\n",
    "\n",
    "# Write contiguous amplicons to CSV\n",
    "with open('fwdorrev_amplicon_positions.csv', 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow([\"Sequence\", \"Start\", \"End\", \"Primer Type\"])\n",
    "    for amplicon in contiguous_amplicons:\n",
    "        csvwriter.writerow(amplicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79f1ddc9-c924-4d74-bb5f-7745bf8f7297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create csv file containing predicted genome coverage for each sequence based on predicted amplicon coverage\n",
    "total_genome_coverages_df = pd.DataFrame([total_genome_coverages])\n",
    "\n",
    "total_genome_coverages_df.to_csv('fwdorrev_genome_coverage_pc.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
